---
title: "ğŸ¥ YouTube Video Analysis Tool ğŸ”"
author: "MatÄ›j PutÃ­k"
format: 
  revealjs:
    slide-number: true
    preview-links: auto
    chalkboard: true
    transition: fade
    theme: simple
    code-overflow: wrap
 
---


## Introduction and Goals ğŸ¯ {.smaller}

- Creating a comprehensive YouTube video analysis tool ğŸ¥
- Extracting and analyzing video metadata and transcripts ğŸ“
- Performing sentiment and topic analysis on comments ğŸ’­
- Generating structured console output ğŸ“Š
- Building threaded comment analysis with reply detection ğŸ”„

## Processing Pipeline ğŸ”„ {.smaller}

![](pipeline.svg){}


## Natural Language Processing ğŸ§  {.smaller}

:::: {.columns}

::: {.column width="50%"}
**Sentiment Analysis:**

- Zero-shot classification
- DeBERTa v3 large model
- Multiple sentiment categories:
  - Positive ğŸ˜Š
  - Neutral ğŸ˜
  - Negative ğŸ˜Ÿ
  - Enthusiastic ğŸ¤©
  - Critical ğŸ¤¨
:::

::: {.column width="50%"}
**Topic Classification:**

- Context-aware relevance
- Multiple topic categories:
  - Questions â“
  - Opinions ğŸ’­
  - Facts ğŸ“š
  - Complaints ğŸ˜¤
  - Praise ğŸ‘
  - Suggestions ğŸ’¡
:::

"This tutorial was incredibly helpful! The explanations were clear and I learned a lot. Could you make more videos like this? ğŸ™Œ"

- Enthusiastic ğŸ¤© (0.92) and Praise ğŸ‘ (0.85)
::::

## Zero-shot Classification Example
```{python}
#| echo: true
#!pip install transformers[sentencepiece]
from transformers import pipeline
text = "Angela Merkel is a politician in Germany and leader of the CDU"
hypothesis_template = "This example is about {}"
classes_verbalized = ["politics", "economy", "entertainment", "environment"]
zeroshot_classifier = pipeline("zero-shot-classification", model="MoritzLaurer/deberta-v3-base-zeroshot-v1.1-all-33")
output = zeroshot_classifier(text, classes_verbalized, hypothesis_template=hypothesis_template, multi_label=False)
print(output)
```



## Llama Prompt Example
```python
import requests

def analyze_comment_relevance(comment, video_summary):
    # Create the prompt template for relevance analysis
    prompt = f"""Based on this video summary:
    
{video_summary}

Analyze the relevance of this comment:
"{comment}"

On a scale from 0.0 to 1.0, how relevant is this comment to the video's content? 
Explain your rating briefly in six words and then provide just the numerical score.


Explanation and Score:"""

    # Call Ollama API
    response = requests.post(
        "http://localhost:11434/api/generate",
        json={
            "model": "llama3",
            "prompt": prompt,
            "stream": False
        }
    )
    return response.json()["response"]

# Example usage
video_summary = """ğŸ“Œ SUMMARY
The video explains the latest developments in quantum computing technology.

ğŸ¯ MAIN TOPIC & CONTEXT
- Primary focus on quantum bits and quantum gates
- Aimed at technical audience with physics background
- Demonstrates recent breakthroughs in qubit stability

ğŸ”‘ KEY POINTS
- New method for reducing decoherence
- Improved error correction techniques
- Scalable architecture for quantum processors"""

# Example comments to analyze
comments = [
    "Nice video! Please do more tutorials!",
    "The explanation of decoherence reduction was brilliant, especially the part about environmental isolation techniques!"
    "The graphics in this video are amazing, but I wish you talked more about error correction."
]

# Analyze each comment
for comment in comments:
    print("\nAnalyzing comment:", comment)
    print("-" * 50)
    result = analyze_comment_relevance(comment, video_summary)
    print(result)
```

##

```{python}
#| echo: false
import requests

def analyze_comment_relevance(comment, video_summary):
    # Create the prompt template for relevance analysis
    prompt = f"""Based on this video summary:
    
{video_summary}

Analyze the relevance of this comment:
"{comment}"

On a scale from 0.0 to 1.0, how relevant is this comment to the video's content? 
Explain your rating briefly in tow sentences and then provide just the numerical
score

Explanation and Score:"""

    # Call Ollama API
    response = requests.post(
        "http://localhost:11434/api/generate",
        json={
            "model": "llama3",
            "prompt": prompt,
            "stream": False
        }
    )
    return response.json()["response"]

# Example usage
video_summary = """ğŸ“Œ SUMMARY
The video explains the latest developments in quantum computing technology.

ğŸ¯ MAIN TOPIC & CONTEXT
- Primary focus on quantum bits and quantum gates
- Aimed at technical audience with physics background
- Demonstrates recent breakthroughs in qubit stability

ğŸ”‘ KEY POINTS
- New method for reducing decoherence
- Improved error correction techniques
- Scalable architecture for quantum processors"""

# Example comments to analyze
comments = [
    "Nice video! Please do more tutorials!",
    "The graphics in this video are amazing, but I wish you talked more about error correction.",
    "The explanation of decoherence reduction was brilliant, especially the part about environmental isolation techniques!"
]

# Analyze each comment
for comment in comments:
    print("\nAnalyzing comment:", comment)
    print("-" * 50)
    result = analyze_comment_relevance(comment, video_summary)
    print(result)
```

## Demo

![](demo.mp4){}

## Questions? â“

Thank you for your attention! ğŸ‘€

Feel free to ask any questions about the implementation details.